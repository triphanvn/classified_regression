# # Configuration file for benchmark experiments
# # ============================================

## Standard GP parameters
gpmodel:
  hyperpars:
    lengthscale: 0.01
    # lengthscale: 0.1 # DBG
    outputscale: 2.24
    noise_std: 
      value: 0.01 # Homoscedastic noise, standard deviation
    # optimization:
    #   Nrestarts: 8
    #   # Nrestarts: 1
    #   # algo_name: 'LN_COBYLA' # Internally, the name is appended to 'nlopt.', e.g., 'nlopt.LN_COBYLA'. See https://nlopt.readthedocs.io/en/latest/NLopt_Python_Reference/
    #   algo_name: 'LN_BOBYQA'
    #   Nmax_evals: 200 # Max number of function evaluations
  # discard_too_close_points: False
  penalization_failed_controller: "None"

## Standard GP parameters
gpclassimodel:
  hyperpars:
    lengthscale: 0.1
    outputscale: 0.45
    noise_std: 
      value: 0.01 # Homoscedastic noise, standard deviation
    # optimization:
    #   Nrestarts: 10
    #   # Nrestarts: 1
    #   # algo_name: 'LN_COBYLA' # Internally, the name is appended to 'nlopt.', e.g., 'nlopt.LN_COBYLA'. See https://nlopt.readthedocs.io/en/latest/NLopt_Python_Reference/
    #   algo_name: 'LN_BOBYQA'
    #   Nmax_evals: 200 # Max number of function evaluations
  # discard_too_close_points: False
  penalization_failed_controller: -2.0 # This has to be a negative value

## Optimize acquisition function
acquisition_function:
  optimization:
    Ndiv_per_dim: 100
    # Nrestarts: 10
    # # Nrestarts: 1
    # # algo_name: 'LN_COBYLA' # Internally, the name is appended to 'nlopt.', e.g., 'nlopt.LN_COBYLA'. See https://nlopt.readthedocs.io/en/latest/NLopt_Python_Reference/
    # algo_name: 'LN_BOBYQA'
    # disp_info_scipy_opti: False # Display info about the progress of the scipy optimizer
  prob_satisfaction: 0.90 # User-defined probability threshold (TODO: Is this really needed?)

plot:
  plotting: True
  saving: False
  path: "./plots/toy_example" # This will automatically be appended to ${hydra.run.dir} by hydra
  block: False

NBOiters: 300
which_objective: "furuta2D"
with_noise: True
Ninit_points:
  total: 1
  safe:
  unsafe:

# cost_heur_high: 0.0 # Tight upper bound on the function seems to be -2.0232
# cost_heur_low: -60.6966 # Value first evaluation -> Not lower because we would decrease the simple regret, thus favouring this case [0.5578, 0.0558]

safety_mechanisms:
  use: True # [DO NOT SET THIS TO FALSE] Set this to True if we want the data to be saved at each iteration
  # load_from_file:
  #   use: False
  #   modify: False
  #   # nr_exp: "20200723160313"
  #   # nr_exp: "20200727111325"
  #   nr_exp: "20200729142504"


